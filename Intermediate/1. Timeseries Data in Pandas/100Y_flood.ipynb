{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Why A 100 Year Flood Can Occur Every Year. Calculate Exceedance Probability and Return Periods in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to flood frequency analysis\n",
    "\n",
    "One way to analyse timeseries data - particularly related to events like floods - is to calculate the frequency of different magnitude events. You have likely heard the term \"100-year-flood\". t actually refers to the flood magnitude that has a probability of exceedance of 1/100 in any given year (i.e., a 1% chance). This is why 100 year flood event can occur 2 years in a row.\n",
    "\n",
    "In this lesson you will learn how \"100-year floods\" (and other flood frequencies) are calculated using some basic stats. Let's define 2 terms:\n",
    "1. Exceedance probability: the probability of a given magnitude event or greater to occur.\n",
    "2. Recurrence interval: the average time of exceedance is the inverse of exceedance probability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Important consideration\n",
    "\n",
    "- The above definitions assume that flood events in the timeseries are independent (i.e. the event magnitudes are not correlated with each other in time)\n",
    "\n",
    "In this project, we will be interpreting max annual floods. How valid do you think the above assumptions are for annual maxima?\n",
    "\n",
    "- In this project, we will be asking you to construct and interpret plots of recurrence intervals. Do you think the processes that drive floods are periodic? If so, over what timescales?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is recurrence interval?\n",
    "\n",
    "100-year floods can happen 2 years in a row\n",
    "\n",
    "Stat techniques, through a process called frequency analysis, are used to estimate the probability of the occurrence of a given precipitation event. The recurrence interval is based on the probability that the given event will be equalled or exceeded in any given year. For example, assume there is a 1 in 50 chance that 6.60 inches of rain will fall in a certain area in a 24-hour period during any given year. Thus, a rainfall total of 6.60 inches in a consecutive 24-hour period is said to have a 50-year recurrence interval. Likewise, using a frequncy analysis there is a 1 in 100 chance that a streamflow of 15,000 cubic feet per seconds (ft3/s) will occur during any year at a certain streamflow-measurement site.Thus, a peak flow of 15,000 ft3/s at the site is said to have a 100-year recurrence interval. Rainfall recurrence intervals are based on both the magnitude and the duration of a rainfall event, whereas streamflow recurrence intervals are based solely on the magnitude of the annual peak flow.\n",
    "\n",
    "10+ years of data are required to perform a frequency analysis for the determination of recurrence intervals. Of course, the more years of historical data the better - a hydrologist will have more confidence on an analysis of a river with 30 years of record than 1 based on 10 years of record.\n",
    "\n",
    "Recurrence intervals for the annual peak streamflow at a given location change if there are significant changes in the flow patterns at that location, possibly caused by an impoundment or diversion of flow. The effects of development (conversion of land from forested or agricultural uses to commercial, residential, or industrial uses) on peak flows is generally much greater for low-recurrence interval floods than for high-recurrence interval floods, such as 25- 50- or 100-year floods. During these larger floods, the soil is saturated and does not have the capacity to absorb additional rainfall. Under these conditions, essentially all of the rain that falls, whether on paved surfaces or on saturated soil, runs off and becomes streamflow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How can we have 2 \"100-year floods\" in < 2 years?\n",
    "\n",
    "This question points out the importance of proper terminology. The term \"100-year flood\" is used in an attempt to simplify the definition of a flood that statistically has a 1% chance of occurring in any given year. Likewise, the term \"100-year storm\" is used to define a rainfall event that statistically has this same 1% chance of occurring. In order words, over the course of 1 mil years, these events would be expected to occur 10,000 times. But just because it rained 10 inches in 1 day las year doesn't mean it can't rain 10 inches in 1 day again this year."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is an annual exceedance probability?\n",
    "\n",
    "The USGUS and other agencies often refer to the % chance of occurrence as an Annual Exceedance Probability or AEP. An AEP is always a fraction of 1. SO a 0.2 AEO flood has a 20% chance of occuring in any given year, and this corresponds to a 5-year recurrence-interval flood. Recurrence-interval terminology tends to be more understandable for flood intensity comparisons. However, AEP terminology reminds the observer that a rare flood does not reduce the chances of another rare flood within a short time period."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate probability in Python\n",
    "\n",
    "You will use streamflow data to explore the probabilities of a different magnitude events (e.g. discharge is measured in cubic feet per sec). You will want long historic records to make your stat inference more robust.\n",
    "\n",
    "You will use the hydrofunctions python package to access streamflow data via an API from the US Geological Survey National Water Info System website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib\n",
    "import requests\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import earthpy as et\n",
    "import hydrofunctions as hf\n",
    "import pandas as pd\n",
    "\n",
    "# Datetime conversion registration\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()\n",
    "\n",
    "# Get the data & set work dir\n",
    "data = et.data.get_data(\"colorado-flood\")\n",
    "os.chdir(os.path.join(et.io.HOME, \"earth-analytics\"))\n",
    "\n",
    "# Prettier plotting with seaborn\n",
    "sns.set(font_scale=1.5, style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find a station of interest\n",
    "\n",
    "The hf.draw_map() function allows you to explore the station visually in a particular area.\n",
    "\n",
    "You will gage dv06730500 The gage along Boulder Creek survived the 2013 flood event and is 1 of longest timeseries dataset along Boulder Creek."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p>Use <a href=\"http://hydrocloud.org\" target=\"_blank\">HydroCloud.org</a> to find a stream gauge. Click on the dots to learn more about a site.</p><iframe src=http://hydrocloud.org/ width=700 height=400></iframe>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create map of stations\n",
    "hf.draw_map()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can get a list of all stations located in Colorado using the hf.NWIS().get_data() method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requested data from https://waterservices.usgs.gov/nwis/dv/?format=json%2C1.1&stateCd=CO\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NWIS' object has no attribute 'siteName'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-510599678798>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# List the names for the first 5 sites in Colorado, USA\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mPR\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msiteName\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'NWIS' object has no attribute 'siteName'"
     ]
    }
   ],
   "source": [
    "# Request data for all stations in Colorado\n",
    "PR = hf.NWIS(stateCd=\"CO\").get_data()\n",
    "\n",
    "# List the names for the first 5 sites in Colorado, USA\n",
    "PR.siteName[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download stream gage data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean daily vs instantaneous stream flow data\n",
    "\n",
    "There are 2 kinds of streamflow timeseries data that the USGS provides online:\n",
    "1. Mean daily streamflow: Mean daily streamflow is useful because it is a complete timeseries (except for days when the gage fails) and thus retains all recorded streamflow events over the period of record.\n",
    "2. Annual max instantaneous streamflow: Instant data is not averaged over the entire day, but instead reflects continuous variation in the flood hydrograph recorded by the stream gage. As such, annual max instant streamflow data are useful because they retiain the max values of discharge recorded in a given year.\n",
    "\n",
    "You will download the mean daily discharge data. The code for this data in dv when using hydrofunctions python package."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get data using hydrofunctions API interface for Python\n",
    "\n",
    "To begin define a start and end date that you'd like to download. ALso define the site ID. Use USGS 06730500 as your selected site. This stream gage survived the 2013 flood event in Colorado. It also has a long record of measurement that will be helpful when calculating recurrence intervals and exceedance probability values below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Station selection\n",
    "\n",
    "In general, to select stream gages for flood frequency analysis you will want to carefully examine the metadata for candidate stations to check for the time period of operation, record completeness, and other comments on gage operation that might impact your interpretation of stat results (e.g., Is there a dam upstream? When was it built? Other flow diversion? Did the gage malfunction during some event?)\n",
    "\n",
    "There are 2 subset of USGS gages that have been specially identified for hydo-climatic analyses because station records are of high quality, cover a long time period, and human modification of the water shed is minimal (e.g. due to flow regulation or urban development): (1) Hydro-Cli9matic Data Network - 2009 and (2) Geospatial attributes of gages for evaluation streamflow.\n",
    "\n",
    "For this project, we followed the lead of scientists assessing the significance of the 2013 Colorado floods using methods similar to the ones introduced in this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requested data from https://waterservices.usgs.gov/nwis/dv/?format=json%2C1.1&sites=06730500&startDT=1946-05-10&endDT=2018-08-29\n"
     ]
    }
   ],
   "source": [
    "# Define the site numnber and start and end dates that you are interested in\n",
    "site = \"06730500\"\n",
    "start = \"1946-05-10\"\n",
    "end = \"2018-08-29\"\n",
    "\n",
    "# Request data for that site and time period\n",
    "longmont_resp = hf.get_nwis(site, \"dv\", start, end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View site and metadata info\n",
    "\n",
    "You can explore the metadata for the site using the get_nwis() function. Below we request the metadata for the site and the \"dv\" or Daily Value data. Recall from above that dv is the mean daily value. iv provides the instant values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requested data from https://waterservices.usgs.gov/nwis/dv/?format=json%2C1.1&sites=06730500&startDT=1946-05-10&endDT=2018-08-29\n",
      "Requested data from https://waterservices.usgs.gov/nwis/dv/?format=json%2C1.1&sites=06730500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'name': 'ns1:timeSeriesResponseType',\n",
       " 'declaredType': 'org.cuahsi.waterml.TimeSeriesResponseType',\n",
       " 'scope': 'javax.xml.bind.JAXBElement$GlobalScope',\n",
       " 'value': {'queryInfo': {'queryURL': 'http://waterservices.usgs.gov/nwis/dv/format=json%2C1.1&sites=06730500',\n",
       "   'criteria': {'locationParam': '[ALL:06730500]',\n",
       "    'variableParam': 'ALL',\n",
       "    'parameter': []},\n",
       "   'note': [{'value': '[ALL:06730500]', 'title': 'filter:sites'},\n",
       "    {'value': '[mode=LATEST, modifiedSince=null]',\n",
       "     'title': 'filter:timeRange'},\n",
       "    {'value': 'methodIds=[ALL]', 'title': 'filter:methodId'},\n",
       "    {'value': '2020-06-21T11:09:09.880Z', 'title': 'requestDT'},\n",
       "    {'value': 'a185f160-b3af-11ea-b630-6cae8b663fb6', 'title': 'requestId'},\n",
       "    {'value': 'Provisional data are subject to revision. Go to http://waterdata.usgs.gov/nwis/help/?provisional for more information.',\n",
       "     'title': 'disclaimer'},\n",
       "    {'value': 'vaas01', 'title': 'server'}]},\n",
       "  'timeSeries': [{'sourceInfo': {'siteName': 'BOULDER CREEK AT MOUTH NEAR LONGMONT, CO',\n",
       "     'siteCode': [{'value': '06730500',\n",
       "       'network': 'NWIS',\n",
       "       'agencyCode': 'USGS'}],\n",
       "     'timeZoneInfo': {'defaultTimeZone': {'zoneOffset': '-07:00',\n",
       "       'zoneAbbreviation': 'MST'},\n",
       "      'daylightSavingsTimeZone': {'zoneOffset': '-06:00',\n",
       "       'zoneAbbreviation': 'MDT'},\n",
       "      'siteUsesDaylightSavingsTime': True},\n",
       "     'geoLocation': {'geogLocation': {'srs': 'EPSG:4326',\n",
       "       'latitude': 40.13877778,\n",
       "       'longitude': -105.0202222},\n",
       "      'localSiteXY': []},\n",
       "     'note': [],\n",
       "     'siteType': [],\n",
       "     'siteProperty': [{'value': 'ST', 'name': 'siteTypeCd'},\n",
       "      {'value': '10190005', 'name': 'hucCd'},\n",
       "      {'value': '08', 'name': 'stateCd'},\n",
       "      {'value': '08123', 'name': 'countyCd'}]},\n",
       "    'variable': {'variableCode': [{'value': '00060',\n",
       "       'network': 'NWIS',\n",
       "       'vocabulary': 'NWIS:UnitValues',\n",
       "       'variableID': 45807197,\n",
       "       'default': True}],\n",
       "     'variableName': 'Streamflow, ft&#179;/s',\n",
       "     'variableDescription': 'Discharge, cubic feet per second',\n",
       "     'valueType': 'Derived Value',\n",
       "     'unit': {'unitCode': 'ft3/s'},\n",
       "     'options': {'option': [{'value': 'Mean',\n",
       "        'name': 'Statistic',\n",
       "        'optionCode': '00003'}]},\n",
       "     'note': [],\n",
       "     'noDataValue': -999999.0,\n",
       "     'variableProperty': [],\n",
       "     'oid': '45807197'},\n",
       "    'values': [{'value': [{'value': '276',\n",
       "        'qualifiers': ['P'],\n",
       "        'dateTime': '2020-06-20T00:00:00.000'}],\n",
       "      'qualifier': [{'qualifierCode': 'P',\n",
       "        'qualifierDescription': 'Provisional data subject to revision.',\n",
       "        'qualifierID': 0,\n",
       "        'network': 'NWIS',\n",
       "        'vocabulary': 'uv_rmk_cd'}],\n",
       "      'qualityControlLevel': [],\n",
       "      'method': [{'methodDescription': '', 'methodID': 17666}],\n",
       "      'source': [],\n",
       "      'offset': [],\n",
       "      'sample': [],\n",
       "      'censorCode': []}],\n",
       "    'name': 'USGS:06730500:00060:00003'}]},\n",
       " 'nil': False,\n",
       " 'globalScope': True,\n",
       " 'typeSubstituted': False}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Request data for the site and time period\n",
    "longmont_resp = hf.get_nwis(site, \"dv\", start, end)\n",
    "\n",
    "# Convert the response to a json in order to use the extract_nwis_df function\n",
    "longmont_resp = longmont_resp.json()\n",
    "\n",
    "# Get metadata about the data\n",
    "hf.get_nwis(site, \"dv\").json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, request the data, returned as pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the data in a pandas dataframe format\n",
    "longmont_discharge = hf.extract_nwis_df(longmont_resp)\n",
    "type(longmont_discharge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "longmont_discharge = pd.DataFrame(longmont_discharge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>USGS:06730500:00060...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'USGS:06730500': {'siteName': 'BOULDER CREEK ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0\n",
       "0                             USGS:06730500:00060...\n",
       "1  {'USGS:06730500': {'siteName': 'BOULDER CREEK ..."
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "longmont_discharge.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hydrofunctions import your data into a pandas dataframe with a datetime index. However, you may find the column headings to be too long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length mismatch: Expected axis has 1 elements, new values have 2 elements",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-49-161b73246149>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Rename columns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mlongmont_discharge\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"discharge\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"flag\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# View first 5 rows\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mlongmont_discharge\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\programdata\\miniconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__setattr__\u001b[1;34m(self, name, value)\u001b[0m\n\u001b[0;32m   5285\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5286\u001b[0m             \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5287\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5288\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5289\u001b[0m             \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\properties.pyx\u001b[0m in \u001b[0;36mpandas._libs.properties.AxisProperty.__set__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mc:\\programdata\\miniconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_set_axis\u001b[1;34m(self, axis, labels)\u001b[0m\n\u001b[0;32m    659\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    660\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_set_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 661\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    662\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_clear_item_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    663\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\programdata\\miniconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mset_axis\u001b[1;34m(self, axis, new_labels)\u001b[0m\n\u001b[0;32m    176\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnew_len\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mold_len\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    177\u001b[0m             raise ValueError(\n\u001b[1;32m--> 178\u001b[1;33m                 \u001b[1;34mf\"Length mismatch: Expected axis has {old_len} elements, new \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    179\u001b[0m                 \u001b[1;34mf\"values have {new_len} elements\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    180\u001b[0m             )\n",
      "\u001b[1;31mValueError\u001b[0m: Length mismatch: Expected axis has 1 elements, new values have 2 elements"
     ]
    }
   ],
   "source": [
    "# Rename columns\n",
    "longmont_discharge.columns = [\"discharge\", \"flag\"]\n",
    "\n",
    "# View first 5 rows\n",
    "longmont_discharge.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
